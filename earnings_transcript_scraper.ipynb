{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kerry Zhang\n",
    "# 7/16/2023\n",
    "# Objective: Scrape earnings call transcripts from roic.ai\n",
    "# Notes: Earnings transcripts are divided by person with div class \"p-3 rounded-lg false\".\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from textblob import TextBlob\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# Avoid throttling\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "chrome_options.add_argument(\"--headless\")  # Enable headless mode\n",
    "\n",
    "# Options\n",
    "\n",
    "INPUT_FILE = \"firms_full.csv\"\n",
    "LOG_FILE = \"scrape_log.csv\"\n",
    "OUTPUT_FOLDER = r\"D:\\finance_tools\\transcripts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tickers\n",
    "# INPUT_FILE = \"firms.xlsx\"\n",
    "# YEARS = list(range(2006, 2023))\n",
    "# QUARTERS = [1, 2, 3, 4]\n",
    "# TICKERS = pd.read_excel(INPUT_FILE, header = None)[0].values.tolist()\n",
    "# print(\"Number of tickers: {}\".format(len(TICKERS)))\n",
    "\n",
    "TICKER_DATA = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "# Require known fiscal quarter\n",
    "TICKER_DATA = TICKER_DATA[TICKER_DATA['fqtr'].notna()]\n",
    "\n",
    "# Require active\n",
    "TICKER_DATA = TICKER_DATA[TICKER_DATA['costat'] == \"A\"]\n",
    "\n",
    "# Require known market value > $1B\n",
    "TICKER_DATA = TICKER_DATA[TICKER_DATA['mkvaltq'].notna()]\n",
    "TICKER_DATA = TICKER_DATA[TICKER_DATA['mkvaltq'] > 1000]\n",
    "\n",
    "# Clean\n",
    "TICKER_DATA = TICKER_DATA[[\"tic\", 'fyearq', 'fqtr']]\n",
    "TICKER_DATA['fqtr'] = TICKER_DATA['fqtr'].astype('int')\n",
    "\n",
    "print(\"Unique Firms: {}\".format(TICKER_DATA[\"tic\"].nunique()))\n",
    "print(\"Total Firm-Quarters: {}\".format(TICKER_DATA.shape[0]))\n",
    "\n",
    "# Remove already scraped\n",
    "if os.path.exists(LOG_FILE):\n",
    "    log_df = pd.read_csv(LOG_FILE)\n",
    "    TICKER_DATA = pd.merge(TICKER_DATA, log_df, how = \"left\", on = [\"tic\", 'fyearq', 'fqtr'])\n",
    "    TICKER_DATA = TICKER_DATA[TICKER_DATA[\"captured\"].isna()]\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"REMAINING: \")\n",
    "    print(\"Unique Firms: {}\".format(TICKER_DATA[\"tic\"].nunique()))\n",
    "    print(\"Total Firm-Quarters: {}\".format(TICKER_DATA.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class text_to_disappear_and_return_new_text(object):\n",
    "    def __init__(self, locator, initial_text):\n",
    "        self.locator = locator\n",
    "        self.initial_text = initial_text\n",
    "\n",
    "    def __call__(self, driver):\n",
    "        try:\n",
    "            element = driver.find_element(*self.locator)\n",
    "            element_text = element.text\n",
    "            if self.initial_text not in element_text:\n",
    "                return element_text\n",
    "        except:\n",
    "            # If element is not found or initial text still present, return False to continue waiting.\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_transcript(url):\n",
    "    \n",
    "    # Set up Selenium WebDriver\n",
    "    driver = webdriver.Chrome(chrome_options)  \n",
    "    \n",
    "    # Navigate to the website\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Wait until element is loaded\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    #locator = (By.ID, \"__next\")\n",
    "    locator = (By.CLASS_NAME, \"space-y-6\")\n",
    "    initial_text = \"Please wait for a while ...\"\n",
    "    \n",
    "    #element = wait.until_not(EC.invisibility_of_element_located(locator))\n",
    "    #element = wait.until(EC.visibility_of_element_located((By.ID, \"__next\")))\n",
    "    element = wait.until(text_to_disappear_and_return_new_text(locator, initial_text))\n",
    "    \n",
    "    # WIP: Throttling\n",
    "    #wait.until(ExpectedConditions.not(ExpectedConditions.textToBePresentInElement(element, \"Completed successfully\")));\n",
    "    \n",
    "    # Extract Text\n",
    "    text = copy.deepcopy(element)\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(earnings_transcript: str) -> list:\n",
    "\n",
    "    # WIP: Remove non-ASCII characters\n",
    "    earnings_transcript = earnings_transcript.replace(\"â\\x80\\x99\", \"'\").replace(\"â\\x80\\x98\", \"'\").replace(\"â\\x80\\x93\", \"'\")\n",
    "    \n",
    "    lst = earnings_transcript.splitlines()\n",
    "    \n",
    "    # Remove speaker abbreviations\n",
    "    lst = [element for element in lst if len(element) > 1]\n",
    "    \n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(lst: list, year: int, quarter: int):\n",
    "    \n",
    "    def is_name(segment: str) -> bool:\n",
    "        words_in_segment = segment.split()\n",
    "    \n",
    "        if (\n",
    "            segment == \"Operator\" or \n",
    "            (\n",
    "             len(words_in_segment) == 2 and \n",
    "             words_in_segment[0].istitle() and \n",
    "             words_in_segment[1].istitle()\n",
    "            )\n",
    "           ):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def get_sentiment(text):\n",
    "        analysis = TextBlob(text)\n",
    "        sentiment_score = analysis.sentiment.polarity\n",
    "        \n",
    "        return sentiment_score\n",
    "    \n",
    "    # Metadata\n",
    "    filing_year_quarter = lst[0].replace(\" · Earnings Call Transcript\", \"\").split()\n",
    "    date = lst[1]\n",
    "    \n",
    "#     filing_qtr = int(filing_year_quarter[0].replace(\"Q\", \"\"))\n",
    "#     filing_year = int(filing_year_quarter[1])\n",
    "    \n",
    "#     if year != filing_year or quarter != filing_qtr:\n",
    "#         return None\n",
    "        \n",
    "    # Store [Position, Caller, Speech, Total Length, Average Segment Length] \n",
    "    position = 0\n",
    "    caller = \"\"\n",
    "    speech = \"\"\n",
    "    paragraph_len_list = []\n",
    "    \n",
    "    # Process segments\n",
    "    data = []\n",
    "    for segment in lst[2:]:\n",
    "        \n",
    "        if is_name(segment):\n",
    "            \n",
    "            # Store current data\n",
    "            data.append([position, \n",
    "                         caller, \n",
    "                         speech, \n",
    "                         np.sum(paragraph_len_list), \n",
    "                         np.mean(paragraph_len_list), \n",
    "                         get_sentiment(speech)])\n",
    "            \n",
    "            # Reset for next caller\n",
    "            position += 1\n",
    "            caller = segment\n",
    "            speech = \"\"\n",
    "            paragraph_len_list = []\n",
    "            \n",
    "        else:\n",
    "            speech += segment + \" \"\n",
    "            paragraph_len_list.append(len(segment.split()))\n",
    "            \n",
    "    df = pd.DataFrame(data[1:], columns=[\"position\", \"name\", \"speech\", \"tot_len\", \"avg_len\", \"sentiment\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(LOG_FILE):\n",
    "    log = log_df.values.tolist()\n",
    "else:\n",
    "    log = []\n",
    "    \n",
    "for index, row in TICKER_DATA.iterrows():\n",
    "    \n",
    "    ticker = row[\"tic\"]\n",
    "    year = row[\"fyearq\"]\n",
    "    quarter = row[\"fqtr\"]\n",
    "    \n",
    "    url = 'https://roic.ai/transcripts/{}:US/{}/{}'.format(*[ticker, year, quarter])\n",
    "\n",
    "    print(\"{} {} Q{} - {}\".format(*[ticker, year, quarter, url]))\n",
    "\n",
    "    filename = os.path.join(OUTPUT_FOLDER, \n",
    "                            \"{:}_{:}_Q{:}.csv\".format(*[ticker, year, quarter])\n",
    "                           )\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"The file '{filename}' already exists.\")\n",
    "        continue\n",
    "\n",
    "    # Get text from URL\n",
    "    earnings_transcript = scrape_transcript(url)\n",
    "\n",
    "    # Convert text into list of lists\n",
    "    earnings_transcript = clean_text(earnings_transcript)\n",
    "\n",
    "    if earnings_transcript == [\"Nothing to show\", \"We apologize for the inconvenience, but there is no content to display at this time.\"] or earnings_transcript == []:\n",
    "        print(\"No data...\")\n",
    "        log.append([ticker, year, quarter, False])\n",
    "        continue\n",
    "\n",
    "    # Convert to dataframe\n",
    "    earnings_transcript = split_text(earnings_transcript, year, quarter)\n",
    "\n",
    "    # Save\n",
    "    earnings_transcript.to_csv(filename, encoding='utf-8-sig')\n",
    "    log.append([ticker, year, quarter, True])\n",
    "    \n",
    "    if (index + 1) % 10 == 0:\n",
    "        log_df_new = pd.DataFrame(log, columns = [\"tic\", \"fyearq\", \"fqtr\", \"captured\"])\n",
    "        log_df_new.to_csv(LOG_FILE)\n",
    "\n",
    "    time.sleep(random.uniform(3, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take advantage of div separation via xpath (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    # Set up Selenium WebDriver\n",
    "    driver = webdriver.Chrome()  \n",
    "\n",
    "    # Navigate to the website\n",
    "    driver.get(\"https://roic.ai/transcripts/ABT?y=2022&q=4\")\n",
    "\n",
    "    # Find all <div> elements with the class \"p-3 rounded-lq false\"\n",
    "    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, \"p-3\"))).click()\n",
    "    div_elements = driver.find_elements(\"xpath\", '//*[@id=\"__next\"]/div/main/div[3]/div/div[2]/div/div[2]')\n",
    "\n",
    "    # Scrape the text content of each matching <div> element\n",
    "    for div_element in div_elements:\n",
    "        text = div_element.text\n",
    "        print(text)\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
